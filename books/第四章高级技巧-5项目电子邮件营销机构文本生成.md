### 4.2.4 生成和微调电子邮件营销活动的合成数据
在本例中，我们将为一家电子邮件营销机构制作一个文本生成工具，利用定向内容为企业创建个性化的电子邮件营销活动。这些电子邮件旨在吸引受众并推广产品或服务。

假设该机构有一个来自支付处理行业的客户，机构的工作人员请求我们举办一场直接面向客户的电子邮件营销活动，为商店提供一项新的在线支付服务。电子邮件营销机构决定在这个项目中使用微调技术，因而需要大量的数据来进行微调。

出于演示目的，我们需要合成数据。通常，最好的结果是通过人类专家给出的数据获得的，但在某些情况下，合成数据也可以帮助我们获得有用的解决方案。

1. **创建合成数据集**

在下面的示例中，我们利用GPT - 3.5 Turbo创建合成数据。为了做到这一点，我们将在提示词中指定，我们希望使用促销话术向特定的商店推广在线支付服务。商店的特征包括商店类型、商店所在城市和商店的规模。为了获得促销话术，我们通过之前定义的`chat_completion`函数将提示词发送给GPT - 3.5 Turbo。


在脚本的开头，我们定义3个列表，分别对应商店类型、商店所在城市和商店的规模：

```python
l_sector = ['Grocery Stores', 'Restaurants', 'Fast Food Restaurants',
            'Pharmacies', 'Service Stations (Fuel)', 'Electronics Stores']
l_city = ['Brussels', 'Paris', 'Berlin']
l_size = ['small','medium', 'large']
```

然后，我们在一个字符串中定义第一个提示词。使用本章介绍的提示工程技巧，我们将在该提示词中明确定义角色、上下文和任务。在这个字符串中，大括号中的3个值将在后面被替换为相应的值。以下是用于生成合成数据的第一个提示词：

```python
f_prompt = """
Role: You are an expert content writer with extensive direct marketing experience. You have strong writing skills, creativity, adaptability to different tones and styles, and a deep understanding of audience needs and preferences for effective direct campaigns.
Context: You have to write a short message in no more than 2 sentences for a direct marketing campaign to sell a new e-commerce payment service to stores.
The target stores have the following three characteristics:
- The sector of activity: {sector}
- The city where the stores are located: {city}
- The size of the stores: {size}
Task: Write a short message for the direct marketing campaign. Use the skills defined in your role to write this message! It is important that the message you create takes into account the product you are selling and the characteristics of the store you are writing to.
"""
```

以下提示词只包含3个变量的值，用逗号分隔。它不用于创建合成数据，只用于微调：

```python
f_sub_prompt = "{sector}, {city}, {size}"
```

下面是代码的主要部分，它遍历之前定义的3个列表。我们可以看到，循环中的代码块很简单。我们用适当的值替换大括号中的值。变量`prompt`与函数`chat_completion`一起使用，生成的广告保存在`response_txt`中。然后将变量`sub_prompt`和`response_txt`添加到`out_openai_completion.csv`文件中，作为用于微调的训练集：

```python
import pandas as pd

df = pd.DataFrame()
for sector in l_sector:
    for city in l_city:
        for size in l_size:
            for i in range(3):  # 每个重复3次
                prompt = f_prompt.format(sector=sector, city=city, size=size)
                sub_prompt = f_sub_prompt.format(sector=sector, city=city, size=size)
                response_txt = chat_completion(
                    prompt, model="gpt-3.5-turbo", temperature=1
                )
                new_row = {"prompt": sub_prompt, "completion": response_txt}
                new_row_df = pd.DataFrame([new_row])
                df = pd.concat([df, new_row_df], axis=0, ignore_index=True)
df.to_csv("out_openai_completion.csv", index=False)
```

注意，对于每种特征的组合，我们都生成3个示例。为了充分发挥模型的创造力，我们将温度值设置为1。在这个脚本的最后，我们将一张Pandas表存储在`out_openai_completion.csv`文件中。它包含162个观测值，其中两列分别包含提示词和相应的文本补全内容。这个文件的前几行如下所示：

```
"Grocery Stores, Brussels, small",Introducing our new e-commerce payment service - the perfect solution for small Brussels-based grocery stores to easily and securely process online transactions.
"Grocery Stores, Brussels, small",Looking for a hassle-free payment solution for your small grocery store in Brussels? Our new e-commerce payment service is here to simplify your transactions and increase your revenue. Try it now!
```

现在，我们可以调用工具来根据`out_openai_completion.csv`文件生成训练文件：

```bash
$ openai tools fine_tunes.prepare_data -f out_openai_completion.csv
```

正如以下代码所示，这个工具为“提示词 - 补全文本对”提供了改进建议。在文本的末尾，它甚至指导我们继续微调并告诉我们如何在微调过程完成后使用模型进行预测：

```
Analyzing...
- Based on your file extension, your file is formatted as a CSV file
- Your file contains 162 prompt-completion pairs
- Your data does not contain a common separator at the end of your prompts. Having a separator string appended to the end of the prompt makes it clearer to the fine-tuned model where the completion should begin. If you intend to do open-ended generation, then you should leave the prompts empty
- Your data does not contain a common ending at the end of your completions. Having a common ending string appended to the end of the completion makes it clearer to the fine-tuned model where the completion should end.
- The completion should start with a whitespace character (` `). This tends to produce better results due to the tokenization we use.
Based on the analysis we will perform the following actions:
- [Necessary] Your format `CSV` will be converted to `JSONL`
- [Recommended] Add a suffix separator ` -->` to all prompts [Y/n]: y
- [Recommended] Add a suffix ending `\n` to all completions [Y/n]: y
- [Recommended] Add a whitespace character to the beginning of the completion [Y/n]: Y
Your data will be written to a new JSONL file. Proceed [Y/n]: y
Wrote modified file to 'out_openai_completion_prepared.jsonl'
Feel free to take a look!
Now that file when fine-tuning:
> openai api fine_tunes.create -t "out_openai_completion_prepared.jsonl"
After you've fine-tuned a model, remember that your prompt has to end with the indicator string ` -->` for the model to start generating completions, rather than continuing with the prompt. Make sure to include `stop=["\n"]` so that the generated texts ends at the expected place.
Once your model starts training, it'll approximately take 4.67 minutes to train a `curie` model, and less for `ada` and `babbage`. Queue will approximately take half an hour per job ahead of you.
```
在这个过程完成后，我们将得到一个名为`out_openai_completion_prepared.jsonl`的新文件，可以把它发送给OpenAI服务器以运行微调过程。

请注意，如函数中的消息所解释的那样，提示词的末尾已经添加了字符串` -->`，并且所有的补全文本都添加了以`\n`结尾的后缀。

2. **使用合成数据集微调模型**

以下代码上传文件并进行微调。在本例中，我们将使用`davinci`作为基础模型，并为生成的模型添加后缀`direct_marketing`：

```python
ft_file = openai.File.create(
    file=open("out_openai_completion_prepared.jsonl", "rb"),
    purpose="fine-tune"
)
openai.FineTune.create(
    training_file=ft_file["id"], model="davinci",
    suffix="direct_marketing"
)
```

这将开始使用我们的数据更新`davinci`模型。这个微调过程可能需要一些时间，但当完成时，我们将拥有一个适用于任务的新模型。微调所需的时间主要取决于数据集中可用的示例数量、示例中的标记数量，以及所选择的基础模型。

在本例中，微调只需不到5分钟。然而，我们也遇到过微调需要超过30分钟的情况。

```bash
$ openai api fine_tunes.create -t out_openai_completion_prepared.jsonl \
    -m davinci --suffix "direct_marketing"
Upload progress: 100%| | 40.8k/40.8k [00:00<00:00, 65.5MiB/s]
Uploaded file from out_openai_completion_prepared.jsonl:
  file-z5mGg(...)
Created fine-tune: ft-mMsm(...)
Streaming events until fine-tuning is complete...
(Ctrl-C will interrupt the stream, but not cancel the fine-tune)
[1] Created fine-tune: ft-mMsm(...)
[1] Fine-tune costs $0.84
[1] Fine-tune enqueued. Queue number: 0
[1] Fine-tune started
[1] Completed epoch 1/4
[1] Completed epoch 2/4
[1] Completed epoch 3/4
[1] Completed epoch 4/4
```

如终端中的消息所示，通过在命令行中输入`Ctrl+C`，你将断开与OpenAI服务器的连接，但这样做不会中断微调过程。


若要重新连接服务器并获取正在运行的微调作业的状态，你可以像下面这样执行命令`fine_tunes.follow`，其中`fine_tune_id`是微调作业的ID：

```bash
$ openai api fine_tunes.follow -i fine_tune_id
```

一旦创建了作业，就能看到这个ID。在之前的示例中，我们使用的`fine_tune_id`是`ft-mMsm(...)`。如果你丢失了`fine_tune_id`，则可以通过以下方式显示所有模型：

```bash
$ openai api fine_tunes.list
```

要立即取消微调作业，请执行以下命令：

```bash
$ openai api fine_tunes.cancel -i fine_tune_id
```

要删除微调作业，请执行以下命令：

```bash
$ openai api fine_tunes.delete -i fine_tune_id
```


3. **使用经过微调的模型进行文本补全**

一旦构建完新模型，便可以通过不同的方式使用它。最简单的测试方法是使用OpenAI Playground。要在此工具中访问你的模型，可以在OpenAI Playground界面右侧的下拉菜单中搜索它。所有经过微调的模型都在此列表的底部。选择模型后，可以使用它进行预测。

![image](https://github.com/user-attachments/assets/3bb14a86-3b88-417f-9ff5-5b865a172096)


我们在以下示例中使用经过微调的模型，提示词为`Hotel, New York, small -->`。在没有进一步指示的情况下，模型自动生成了一则广告，用于推广纽约的一家小型酒店的在线支付服务。

我们已经通过一个只有162个例子的小型数据集获得了出色的结果。对于微调任务，我们通常建议提供几百个例子，最好提供几千个。此外，本例中的训练集是合成的。在理想情况下，训练集应该由专家编写。

使用OpenAI API时，我们按照之前的方式使用`Completion.create`，只不过需要将新模型的名称作为输入参数。不要忘记以` -->`结束所有提示词，并将`\n`设置为停止词：

```python
openai.Completion.create(
    model="davinci:ft-book:direct-marketing-2023-05-01-15-20-35",
    prompt="Hotel, New York, small -->",
    max_tokens=100,
    temperature=0,
    stop="\n"
)
```


我们得到以下答案：

```json
<OpenAIObject text_completion id=cml-7BTkrdo(...) at 0x7f2(4ca5c220>
  JSON: {
  "choices": [
    {
      "finish_reason": "stop",
      "index": 0,
      "logprobs": null,
      "text": " \"Upgrade your hotel's payment system with our new \ e-commerce service, designed for small businesses. "
    }
  ],
  "created": 1682970309,
  "id": "cml-7BTkrdo(...)",
  "model": "davinci:ft-book:direct-marketing-2023-05-01-15-20-35",
  "object": "text_completion",
  "usage": {
    "completion_tokens": 37,
    "prompt_tokens": 8,
    "total_tokens": 45
  }
}
```
正如你看到的，Python开发人员可以使用微调技术根据具体的业务需求来定制LLM，特别是在电子邮件营销等动态领域中。这种强大的方法可用于定制应用程序所需的语言模型，最终帮助你更好地为客户提供服务并推动业务增长。

### 4.2.5 微调的成本

使用微调模型的成本不低。你不仅需要支付模型训练费用，而且在模型准备好后，每次进行预测时需要支付的费用也会比使用OpenAI提供的基础模型略高一些。

在我们撰写本书之时，费用如表4 - 2所示，不过具体的费用会有所变化。

|模型|训练（每千个标记）|使用（每千个标记）|
| ---- | ---- | ---- |
|ada|0.0004美元|0.0016美元|
|babbage|0.0006美元|0.0024美元|
|curie|0.0030美元|0.0120美元|
|davinci|0.0300美元|0.1200美元|

作为比较，gpt - 3.5 - turbo模型的定价是每千个输出标记0.0020美元。可见，gpt - 3.5 - turbo模型的性价比最高。

要了解最新的模型定价，请访问OpenAI的Pricing页面。

### 4.3 小结

本章讨论了GPT - 4和ChatGPT的高级技巧，并提供了关键的建议来帮助你改进LLM驱动型应用程序的开发过程。

开发人员可以通过了解提示工程、零样本学习、少样本学习和微调来创建更高效、针对性更强的应用程序

。通过考虑上下文、任务和角色，开发人员可以创建有效的提示词，从而更精确地与模型交互。通过逐步推理，

开发人员可以鼓励模型更有效地推理和处理复杂任务。此外，本章还讨论了少样本学习提供的灵活性和适应性，强调其对数据的高效利用和快速适应不同任务的能力。

|技巧|定义|用例|数据|所需费用|总结|
| ---- | ---- | ---- | ---- | ---- | ---- |
|零样本学习|预测没有先验示例的未知任务|简单的任务|不需要额外的示例数据|用法：按标记（输入 + 输出）定价|默认使用|
|少样本学习|提示词包括输入和目标输出的示例|定义明确但复杂的任务，通常具有特定的输出格式|需要少量示例|用法：按标记（输入 + 输出）定价；可能导致提示词很长|如果零样本学习因输出要求而不起作用，则使用少样本学习|
|提示工程技巧|详细的提示词可以包括上下文、角色和任务，或者运用“逐步思考”之类的技巧|创造性的复杂任务|数据量取决于提示工程技巧|用法：按标记（输入 + 输出）定价；可能导致提示词很长|如果零样本学习因任务过于复杂而不起作用，请尝试使用提示工程技巧|
|微调|在一个更小、更具体的数据集上进一步训练模型，使用的提示词很简单|高度复杂的任务|需要一个大型训练集|训练：对于微调后的davinci模型，按标记（输入 + 输出）定价的成本大约是GPT - 3.5 Turbo的80倍。这意味着，如果其他技术导致提示词长度是其80倍，则微调在经济上更可取|如果拥有非常专业的大型数据集，并且其他解决方案无法提供足够好的结果，则应将微调作为最后的手段|

为了确保成功构建LLM驱动型应用程序，开发人员应该尝试其他技术并评估模型的响应准确性和相关性。此外，开发人员应该意识到LLM的计算限制，并相应地调整提示词以取得更好的结果。通过整合这些先进技术并不断完善方法，开发人员可以构建强大且富有创意的应用程序，真正释放GPT - 4和ChatGPT的潜力。

在第5章中，你将了解到将LLM集成到应用程序中的另外两种方式：插件和LangChain框架。这些工具使开发人员能够构建富有创意的应用程序，访问最新信息，并简化LLM驱动型应用程序的开发。我们还将畅想LLM的未来及LLM对应用程序开发的意义。

注10：截至2023年12月2日，OpenAI支持微调的模型已更新，并且整体下调了微调的价格。——译者注

注11：零样本学习和少样本学习都属于提示工程中的具体技术。提示工程作为一门快速发展的学科，旨在为生成式AI模型设计和优化提示词，以获得更高质量的模型响应。截至2023年12月2日，除了本书提到的这几种方法，提示工程已经发展出了更多方法，如自洽性（self - consistency）、思维树（tree of thoughts）、推理与行动（ReAct）等。——译者注

注12完整内容为：截至2023年12月2日，OpenAI已经对微调数据集的需求进行了优化。通常情况下，你只需要提供50 - 100个训练示例进行微调，就会看到明显的改进效果。但整体而言，微调在技术难度和实现成本上，仍然高于前面几种方法。 
