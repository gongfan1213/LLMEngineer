### 第1章 初识GPT-4和ChatGPT

想象这样一个世界：在这个世界里，你可以像和朋友聊天一样快速地与计算机交互。那会是怎样的体验？你可以创造出什么样的应用程序？这正是OpenAI努力构建的世界，它通过其GPT模型让设备拥有与人类对话的能力。作为人工智能（artificial intelligence, AI）领域的最新成果，GPT-4和其他GPT模型是基于大量数据训练而成的大语言模型¹（large language model, LLM），它们能够以非常高的准确性识别和生成人类可读的文本。

这些AI模型的意义远超简单的语音助手。多亏了OpenAI的模型，开发人员现在可以利用自然语言处理（natural language processing, NLP）技术创建应用程序，使其以一种曾经只存在于科幻小说中的方式理解我们的需求。从学习和适应个体需求的创新型客户支持系统，到理解每个学生独特的学习风格的个性化教学工具，GPT-4和ChatGPT打开了一扇门，让人们看见一个充满可能性的全新世界。

GPT-4和ChatGPT究竟是什么？本章的目标是深入探讨这些AI模型的基础、起源和关键特性。通过了解这些模型的基础知识，你将为构建下一代以LLM驱动的应用程序打下坚实的基础。

注1：“大语言模型”简称“大模型”。在本书中，两者的意思相同。——编者注

#### 1.1 LLM概述
本节介绍塑造GPT-4和ChatGPT发展历程的基础模块。我们旨在帮助你全面理解语言模型、NLP技术、Transformer架构的作用，以及GPT模型中的标记化和预测过程。

##### 1.1.1 探索语言模型和NLP的基础
作为LLM，GPT-4和ChatGPT是NLP领域中最新的模型类型，NLP是机器学习和人工智能的一个子领域。在深入研究GPT-4和ChatGPT之前，有必要了解NLP及其相关领域。

AI有不同的定义，但其中一个定义或多或少已成为共识，即AI是一类计算机系统，它能够执行通常需要人类智能才能完成的任务。根据这个定义，许多算法可以被归为AI算法，比如导航应用程序所用的交通预测算法或策略类视频游戏所用的基于规则的系统。从表面上看，在这些示例中，计算机似乎需要智能才能完成相关任务。

机器学习（machine learning, ML）是AI的一个子集。在ML中，我们不试图直接实现AI系统使用的决策规则。相反，我们试图开发算法，使系统能够通过示例自己学习。自从在20世纪50年代开始进行ML研究以来，人们已经在科学文献中提出了许多ML算法。

在这些ML算法中，深度学习（deep learning, DL）算法已经引起了广泛关注。DL是ML的一个分支，专注于受大脑结构启发的算法。这些算法被称为人工神经网络（artificial neural network）。它们可以处理大量的数据，并且在图像识别、语音识别及NLP等任务上表现出色。

GPT-4和ChatGPT基于一种特定的神经网络架构，即Transformer。Transformer就像阅读机一样，它关注句子或段落的不同部分，以理解其上下文并产生连贯的回答。此外，它还可以理解句子中的单词顺序和上下文意思。这使Transformer在语言翻译、问题回答和文本生成等任务中非常有效。图1-1展示了以上术语之间的关系。

![image](https://github.com/user-attachments/assets/516dc439-de35-4e2f-9a85-93d01cf0e91f)


**图1-1：从AI到Transformer的嵌套技术集合**

人工智能（AI）：任何能使计算机模仿人类行为的技术

机器学习（ML）：无须明确编程即可学习的能力

深度学习（DL）：使用人工神经网络从数据中提取模式的能力

Transformer：GPT-4和ChatGPT基于此

NLP是AI的一个子领域，专注于使计算机能够处理、解释和生成人类语言。现代NLP解决方案基于ML算法。NLP的目标是让计算机能够处理自然语言文本。这个目标涉及诸多任务，如下所述。

**文本分类**

将输入文本归为预定义的类别。这类任务包括情感分析和主题分类。比如，某公司使用情感分析来了解客户对其服务的意见。电子邮件过滤是主题分类的一个例子，其中电子邮件可以被归类为“个人邮件”“社交邮件”“促销邮件”“垃圾邮件”等。

**自动翻译**

将文本从一种语言自动翻译成另一种语言。请注意，这类任务可以包括将代码从一种程序设计语言翻译成另一种程序设计语言，比如从Python翻译成C++。

**问题回答**

根据给定的文本回答问题。比如，在线客服门户网站可以使用NLP模型回答关于产品的常见问题；教学软件可以使用NLP模型回答学生关于所学主题的问题。

**文本生成**
根据给定的输入文本（称为提示词²）生成连贯且相关的输出文本。

如前所述，LLM是试图完成文本生成任务的一类ML模型。LLM使计算机能够处理、解释和生成人类语言，从而提高人机交互效率。为了做到这一点，LLM会分析大量文本数据或基于这些数据进行训练，从而学习句子中各词之间的模式和关系。这个学习过程可以使用各种数据源，包括维基百科、Reddit、成千上万本书，甚至互联网本身。在给定输入文本的情况下，这个学习过程使得LLM能够预测最有可能出现的后续单词，从而生成对输入文本有意义的回应。于2023年发布的一些现代语言模型非常庞大，并且已经在大量文本上进行了训练，因此它们可以直接执行大多数NLP任务，如文本分类、自动翻译、问题回答等。GPT-4和ChatGPT是在文本生成任务上表现出色的LLM。

LLM的发展可以追溯到几年前。它始于简单的语言模型，如n - gram模型。n - gram模型通过使用词频来根据前面的词预测句子中的下一个词，其预测结果是在训练文本中紧随前面的词出现的频率最高的词。虽然这种方法提供了不错的着手点，但是n - gram模型在理解上下文和语法方面仍需改进，因为它有时会生成不连贯的文本。

为了提高n - gram模型的性能，人们引入了更先进的学习算法，包括循环神经网络（recurrent neural network, RNN）和长短期记忆（long short - term memory, LSTM）网络。与n - gram模型相比，这些模型能够学习更长的序列，并且能够更好地分析上下文，但它们在处理大量数据时的效率仍然欠佳。尽管如此，在很长的一段时间里，这些模型算是最高效的，因此在自动翻译等任务中被广泛使用。

注2：对于prompt一词，本书统一采用“提示词”这个译法，以符合业内惯例。不过，prompt既可以是一个词，也可以是一个或多个句子。对于prompt engineering，本书采用“提示工程”这个译法。——译者注

##### 1.1.2 理解Transformer架构及其在LLM中的作用

Transformer架构彻底改变了NLP领域，这主要是因为它能够有效解决之前的NLP模型（如RNN）存在的一个关键问题：很难处理长文本序列并记住其上下文。换句话说，RNN在处理长文本序列时容易忘记上下文（也就是臭名昭著的“灾难性遗忘问题”），Transformer则具备高效处理和编码上下文的能力。

这场革命的核心支柱是注意力机制，这是一个简单而又强大的机制。模型不再将文本序列中的所有词视为同等重要，而是在任务的每个步骤中关注最相关的词。交叉注意力和自注意力是基于注意力机制的两个架构模块，它们经常出现在LLM中。Transformer架构广泛使用了交叉注意力模块和自注意力模块。

**交叉注意力**

有助于模型确定输入文本的不同部分与输出文本中下一个词的相关性。它就像一盏聚光灯，照亮输入文本中的词或短语，并突出显示预测下一个词所需的相关信息，同时忽略不重要的细节。

为了说明这一点，让我们以一个简单的句子翻译任务为例。假设输入文本是这样一个英语句子：Alice enjoyed the sunny weather in Brussels（Alice很享受布鲁塞尔阳光明媚的天气）。如果目标语言是法语，那么输出文本应该是：Alice a profité du temps ensoleillé à Bruxelles。在这个例子中，让我们专注于生成法语单词ensoleillé，它对应原句中的sunny。对于这个预测任务，交叉注意力模块会更关注英语单词sunny和weather，因为它们都与ensoleillé相关。通过关注这两个单词，交叉注意力模块有助于模型为句子的这一部分生成准确的翻译结果，如图1-2所示。

![image](https://github.com/user-attachments/assets/c9d5114a-c096-4999-9e97-cb9f9970c6e1)


**图1-2：交叉注意力模块使模型关注输入文本（英语句子）中的关键部分，以预测输出文本（法语句子）中的下一个单词**
输入：Alice enjoyed the sunny weather in Brussels
输出：Alice a profité du temps 需要预测的下一个单词
由于注意力机制的作用，模型将更关注sunny和weather这两个单词，而不太关注其他单词

**自注意力机制**

是指模型能够关注其输入文本的不同部分。具体到NLP领域，自注意力机制使模型能够评估句子中的每个词相比于其他词的重要性，这使得模型能够更好地理解各词之间的关系，并根据输入文本中的多个词构建新概念。

来看一个更具体的例子。考虑以下句子：Alice received praise from her colleagues（Alice受到同事的赞扬）。假设模型试图理解her这个单词的意思。自注意力机制给句子中的每个单词分配不同的权重，突出在这个上下文中与her相关的单词。在本例中，自注意力机制会更关注Alice和colleagues这两个单词。如前所述，自注意力机制帮助模型根据这些单词构建新概念。在本例中，可能出现的一个新概念是Alice's colleagues，如图1-3所示。

![image](https://github.com/user-attachments/assets/9a7ab68c-4f58-45a2-9002-9d89e0c402e9)


**图1-3：自注意力机制使新概念Alice's colleagues得以出现**

输入：Alice received praise from her colleagues

自注意力机制处理过程展示，最终形成新概念Alice's colleagues

与RNN不同，Transformer架构具有易于并行化的优势。这意味着Transformer架构可以同时处理输入文本的多个部分，而无须顺序处理。这样做可以提高计算速度和训练速度，因为模型的不同部分可以并行工作，而无须等待前一步骤完成。基于Transformer架构的模型所具备的并行处理能力与图形处理单元（graphics processing unit, GPU）的架构完美契合，后者专用于同时处理多个计算任务。由于高度的并行性和强大的计算能力，GPU非常适合用于训练和运行基于Transformer架构的模型。硬件上的这一进展使科学家能够在大型数据集上训练模型，从而为开发LLM铺平了道路。

Transformer架构由来自谷歌公司的Ashish Vaswani等人在2017年的论文“Attention Is All You Need”中提出，最初用于序列到序列的任务，如机器翻译任务。标准的Transformer架构有两个主要组件：编码器和解码器，两者都十分依赖注意力机制。

编码器的任务是处理输入文本，识别有价值的特征，并生成有意义的文本表示，称为嵌入（embedding）。

解码器使用这个嵌入来生成一个输出，比如翻译结果或摘要文本。这个输出有效地解释了编码信息。

生成式预训练Transformer（Generative Pre - trained Transformer, GPT）是一类基于Transformer架构的模型，专门利用原始架构中的解码器部分。在GPT中，不存在编码器，因此无须通过交叉注意力机制来整合编码器产生的嵌入。也就是说，GPT仅依赖解码器内部的自注意力机制来生成上下文感知的表示和预测结果。请注意，BERT等其他一些众所周知的模型基于编码器部分，但本书不涉及这类模型。图1-4展示了NLP技术的演变历程。

![image](https://github.com/user-attachments/assets/e82ce228-9e4c-4fae-8c4c-8aef3f213acd)


**图1-4：NLP技术从n - gram到LLM的演变**

n - gram：基于前面的词预测下一个词，理解上下文和语法的能力有限

RNN和LSTM：改进的序列学习，难以处理大量数据

Transformer：有效地识别各词之间的关系，能够在大型数据集上训练

LLM：GPT

##### 1.1.3 解密GPT模型的标记化和预测步骤
GPT模型接收一段提示词作为输入，然后生成一段文本作为输出。这个过程被称为文本补全。举例来说，提示词可以是The weather is nice today, so I decided to（今天天气很好，所以我决定），模型的输出则可能是go for a walk（去散步）。你可能想知道GPT模型是如何根据输入的提示词构建输出文本的。正如你将看到的，这主要是一个概率问题。

当GPT模型收到一段提示词之后，它首先将输入拆分成标记（token）。这些标记代表单词、单词的一部分、空格或标点符号。比如，在前面的例子中，提示词可以被拆分成[The, wea, ther, is, nice, today, ,, so, I, de, ci, ded, to]。

几乎每个语言模型都配有自己的分词器。截至本书英文版出版之时，GPT-4的分词器还不可用³，不过你可以尝试使用GPT-3的分词器。

理解标记与词长的一条经验法则是，对于英文文本，100个标记大约等于75个单词。

因为有了注意力机制和Transformer架构，LLM能够轻松处理标记并解释它们之间的关系及提示词的整体含义。Transformer架构使模型能够高效地识别文本中的关键信息和上下文。

为了生成新的句子，LLM根据提示词的上下文预测最有可能出现的下一个标记。OpenAI开发了两个版本的GPT-4，上下文窗口大小分别为8192个标记和32768个标记⁴。与之前的循环模型不同，带有注意力机制的Transformer架构使得LLM能够将上下文作为一个整体来考虑。基于这个上下文，模型为每个潜在的后续标记分配一个概率分数，然后选择概率最高的标记作为序列中的下一个标记。在前面的例子中，“今天天气很好，所以我决定”之后，下一个最佳标记可能是“去”。

接下来重复此过程，但现在上下文变为“今天天气很好，所以我决定去”，之前预测的标记“去”被添加到原始提示词中。这个过程会一直重复，直到形成一个完整的句子：“今天天气很好，所以我决定去散步。”这个过程依赖于LLM学习从大量文本数据中预测下一个最有可能出现的单词的能力。图1-5展示了这个过程。

![image](https://github.com/user-attachments/assets/9948aa11-21e5-4985-9616-89186a381a2a)


**图1-5：逐个标记地补全文本，整个过程是迭代式的**

1. 收到提示词：示例：“The weather is nice today, so I decided to”

2. 将输入拆分为标记：示例：[“The”, “wea”, “ther”, “is”, “nice”, “today”, “,”, “so”, “I”, “de”, “ci”, “ded”, “to”]

3. 采用Transformer架构处理标记：理解标记之间的关系，识别提示词的整体含义

4. 基于上下文预测下一个标记：为可能的单词分配概率分数，示例：{“go”:0.7, “stay”:0.2, “wait”:0.1}

5. 根据概率分数选择标记：示例：“go”

重复步骤4和步骤5，直到形成完整的句子：示例：“The weather is nice today, so I decided to go for a walk.”

注3：现在，OpenAI已在其网站上提供了GPT-4的分词器。——译者注

注4：请注意，本书中的译者注的添加时间为2024年11月19日~2023年12月2日，在此统一说明，后续不再逐一详细说明。截至2023年11月下旬，OpenAI已提供6个GPT-4模型，包括gpt-4-1106-preview、gpt-4-vision-preview、gpt-4、gpt-4-32k、gpt-4-0613、gpt-4-32k-0613，其中gpt-4-1106-preview的上下文窗口已增加至12800个标记。——译者注



#### 1.2 GPT模型简史：从GPT-1到GPT-4
本节将回顾OpenAI的GPT模型从GPT-1到GPT-4的演变历程。

##### 1.2.1 GPT-1
2018年年中，就在Transformer架构诞生一年后，OpenAI发表了一篇题为“Improving Language Understanding by Generative Pre - Training”的论文，作者是Alec Radford等人。这篇论文介绍了GPT，也被称为GPT-1。

在GPT-1出现之前，构建高性能NLP神经网络的常用方法是利用监督学习。这种学习技术使用大量的手动标记数据。以情感分析任务为例，目标是对给定的文本进行分类，判断其情感是积极的还是消极的。一种常见的策略是收集数千个手动标记的文本示例来构建有效的分类模型。然而，这需要有大量标记良好的监督数据。这一需求限制了监督学习的性能，因为要生成这样的数据集，难度很大且成本高昂。

在论文中，GPT-1的作者提出了一种新的学习过程，其中引入了无监督的预训练步骤。这个预训练步骤不需要标记数据。相反，他们训练模型来预测下一个标记。由于采用了可以并行化的Transformer架构，预训练步骤是在大量数据上进行的。对于预训练，GPT-1模型使用了BookCorpus数据集。该数据集包含约11000本未出版图书的文本。BookCorpus最初由Yukun Zhu等人在2015年的论文“Aligning Books and Movies: Towards Story - like Visual Explanations by Watching Movies and Reading Books”中给出，并通过多伦多大学的网页提供。然而，原始数据集的正式版本如今已不能公开访问。

人们发现，GPT-1在各种基本的文本补全任务中是有效的。在无监督学习阶段，该模型学习BookCorpus数据集并预测文本中的下一个词。然而，GPT-1是小模型，它无法在不经过微调的情况下执行复杂任务。因此，人们将微调作为第二个监督学习步骤，让模型在一小部分手动标记的数据上进行微调，从而适应特定的目标任务。比如，在情感分析等分类任务中，可能需要在一小部分手动标记的文本示例上重新训练模型，以使其达到不错的准确度。这个过程使模型在初始的预训练阶段习得的参数
