### 4.2.2 使用OpenAI API进行微调

1. **准备数据**

更新LLM需要提供一个包含示例的数据集。该数据集应该是一个JSONL文件，其中每一行对应一个提示词 - 补全文本对：

```json
[{"prompt": "<prompt text>", "completion": "<completion text>"},
{"prompt": "<prompt text>", "completion": "<completion text>"},
{"prompt": "<prompt text>", "completion": "<completion text>"}]
```

JSONL文件是文本文件，其中每一行表示一个单独的JSON对象。你可以使用它来高效地存储大量数据。OpenAI提供了一个工具，可以帮助你生成此训练文件。该工具接受各种文件格式（CSV、TSV、XLSX、JSON或JSONL）作为输入，只要它们包含提示词和文本补全列/键，并且输出可直接用于微调过程的JSONL文件。该工具还会验证数据，并提供改进数据质量的建议。

在终端中使用以下代码运行此工具：

```bash
$ openai tools fine_tunes.prepare_data -f <LOCAL_FILE>
```

该工具将提出一系列建议来改善最终文件的结果。你既可以接受这些建议，也可以不接受，还可以指定选项 -q，从而自动接受所有建议。

当执行`pip install openai`时，该工具会自动安装。之后，你便可以在终端中使用它。

如果你有足够的数据，那么该工具会询问你是否要将数据分为训练集和验证集。这是一种推荐的做法。算法将使用训练集来微调模型参数。验证集则用于衡量模型在未用于更新参数的数据上的性能。

对LLM的微调受益于高质量示例，最好由专家审核。当使用已有数据集进行微调时，请确保对数据进行筛查，以排除具有冒犯性的内容或不准确的内容。如果数据集过大而无法手动审核所有内容，则可以检查随机样本。

2. **上传数据**

准备好数据后，需要将其上传到OpenAI服务器。OpenAI API提供了不同的函数来操作文件。以下是一些重要函数。

- **上传文件**：

```python
openai.File.create(
    file=open("out_openai_completion_prepared.jsonl", "rb"),
    purpose='fine-tune'
)
```

两个参数是必需的：`file`和`purpose`。

在微调时，将`purpose`设置为`fine-tune`。这将验证用于微调的下载文件格式。

此函数的输出是一个字典，你可以在`id`字段中检索文件ID。目前，文件的总大小可以达到1 GB⁷。如需更多信息，请联系OpenAI。

- **删除文件**：

```python
openai.File.delete("file-z5mGg(...)")
```

`file_id`参数是必需的。

- **列出所有已上传的文件**：

```python
openai.File.list()
```

检索文件ID可能会有帮助，比如在开始微调过程时。


3. **创建经过微调的模型**

微调已上传文件是一个简单的过程。端点`openai.FineTune.create`在OpenAI服务器上创建一个作业，以根据给定的数据集优化指定的模型。该函数的响应包含排队作业的详细信息，如作业的状态、`fine_tune_id`，以及过程结束时模型的名称。

表4 - 1列出了主要的输入参数。

|字段名称|类型|描述|
| ---- | ---- | ---- |
|`training_file`|字符串|这是唯一的必填参数，包含已上传文件的ID。数据必须格式化为JSONL文件。每个训练示例都是一个带有`prompt`键和`completion`键的JSON对象|
|`model`|字符串|指定用于微调的基础模型。可选项有`ada`、`babbage`、`curie`、`davinci`，或者之前微调过的模型。默认的基础模型是`curie`|
|`validation_file`|字符串|包含验证数据的已上传文件。该文件中的数据将在微调过程中周期性地用于生成验证指标|
|`suffix`|字符串|这是一个最多由40个字符组成的字符串，它将被添加到自定义模型名称中|

4. **列出微调作业**

可以通过以下函数获取OpenAI服务器上的所有微调作业：

```python
openai.FineTune.list()
```

结果是一个字典，包含所有微调模型的信息。

5. **取消微调作业**

可以通过以下函数立即中断在OpenAI服务器上运行的作业：

```python
openai.FineTune.cancel()
```

该函数只有一个必需的参数：`fine_tune_id`。该参数是以`ft-`开头的字符串，例如`ft-Re12otqdRaJ(...)`。它是在使用`openai.FineTune.create`创建作业后获得的。

如果你丢失了`fine_tune_id`，那么可以使用`openai.FineTune.list`检索它。

注7：截至2023年12月2日，一个组织上传的所有文件大小可以达到100 GB，单个文件大小可以达到512 MB或最大200万个标记。——译者注

注8：截至2023年12月2日，OpenAI在创建微调作业的输入参数中增加了`hyperparameter`（超参数），可以对微调中的批次示例数量、学习率乘数、训练模型的周期数进行配置。——译者注

注9：同注4。——译者注

### 4.2.3 微调的应用

微调提供了一种强大的技术手段，有助于提升模型在各类应用场景中的性能。本节介绍几个使用微调的成功案例。从这些例子中汲取灵感吧！你也许在自己的用例中遇到了同一类型的问题。再次提醒，微调的成本比基于提示工程的技术更高，因此在大多数情况下并非必需。不过当需要使用它时，微调可以显著地改善效果。


1. **法律文本分析**

在这个案例中，LLM被用来处理法律文本并提取有价值的信息。这些文档通常使用特定的行话写成，这使非专业人士很难理解其内容。第1章提到，在美国统一律师资格考试中，GPT - 4的得分位于第90百分位。通过微调可以使模型专门针对特定领域完成任务，或协助非专业人士参与法律程序。

通过在特定主题的法律语料库上对LLM进行微调，或者针对特定类型的最终用户，该模型可以更好地处理法律文本，并在执行与该特定类型的最终用户相关的任务时变得更加熟练。

使用大量数据微调LLM，以分析法律文本，这样做可以显著地提高模型在这些任务上的性能，使其能够更好地处理超出提示工程技术能力范围的细微差别。

2. **自动代码审查**

在这个案例中，微调可以帮助模型分析开发人员编写的代码，并提出改进建议。这需要在包含代码片段和注释的数据集上训练模型，使模型能够处理特定语言的语法、语义和最佳实践。请注意，这个案例类似于GitHub对Copilot的用法，该工具旨在通过实时提供对代码和整个函数的建议来帮助开发人员编写代码。你可以使用微调来训练模型完成特定任务，比如代码审查，并使用特定的标准或编程框架为自己构建项目。

比如，JSONL文件可以包含代码及相应的审查评论。这将帮助模型学习如何提供准确且相关的代码质量反馈。以下是一个例子。

```json
{
    "prompt": "Review the following Python code: 'def sum(a, b): return a + b\\nresult = sum(5, '5')'",
    "completion": "Type error: The'sum' function is adding an integer and a string. Consider converting the string to an integer using int() before passing it to the function."
}
```

3. **财务文档摘要**

针对收益报告、财务报表和分析师报告等财务文档，经过微调的LLM可以生成简明、准确的摘要。在与财务记录明确相关的数据集上微调后，LLM可以更准确地理解财务文档的术语和上下文。比如，模型可以将央行关于上调利率的详细报告压缩成简洁而富有信息的摘要。

要调整现有模型以获得更好的财务文档摘要，你需要拥有大量样本摘要。这样一来，你便可以给模型提供一个包含财务文档及其理想摘要的JSONL文件，举例如下。

```json
{
    "prompt": "The central bank announced a 0.25% increase in the benchmark interest rate, citing concerns about inflationary pressures. This move is expected to affect borrowing costs for consumers and businesses.",
    "completion": "Bank increases rate 0.25% for inflation worry. May affect people, business borrowing costs."
}
```

4. **技术文档翻译**

与少样本学习相比，使用微调后的模型来翻译技术文档可以显著地改善翻译效果。主要原因是，技术文档通常包含专业词汇和复杂的句子结构，少样本学习无法有效处理这种复杂性。基础模型是未经调整的GPT - 3模型，它们采用了RLHF技术。在使用前，这些模型需要进行微调。要微调现有的基础模型，你需要准备一个包含训练数据的JSONL文件。对于技术文档翻译的用例，该文件应该包括将技术文本翻译为目标语言的翻译内容。

5. **为专业领域生成内容**

一个经过微调的模型可以针对高度专业化的主题生成高质量、引人入胜且与上下文相关的内容。对于这种任务，基础模型可能没有足够的训练数据来保持准确性。与其他所有用例一样，你需要创建一个训练数据集，以使模型专门用于生成专业内容。为此，你需要找到许多关于专业领域的文章。这些数据将用于创建包含“提示词 - 补全文本对”的JSONL文件。以客户服务领域为例，提供迅速、准确且友好的响应对于提升客户满意度至关重要。

微调模型可以显著提高客户服务聊天机器人的性能，使模型更好地理解和响应特定领域的客户查询。客户服务场景具备天然的优势，即容易收集典型客户服务对话的高质量问答集，通过用户反馈形成回路，再通过微调持续改进模型的响应质量。这使模型能够更准确地识别客户问题的本质，并提供合适的解决方案。比如，模型可以学习如何处理账户查询、故障排除或产品推荐等具体问题。

### 4.2.4 生成和微调电子邮件营销活动的合成数据
（此部分未完整展示相关内容，仅记录标题 ） 
