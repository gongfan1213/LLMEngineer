### 4.1.4 改善提示效果
少样本学习是LLM的一个强大的特点，因为它使得LLM高度灵活且适应性强，只需有限的额外信息即可执行各种任务。

在提示词中提供示例时，务必确保上下文清晰且相关。清晰的示例有助于模型匹配所需输出格式并解决问题。相反，信息不充分或模棱两可的示例可能导致意外或错误的结果。因此，仔细编写示例并确保它们传达正确的信息，对模型准确执行任务至关重要。

指导LLM的另一种方法是单样本学习（one - shot learning）。顾名思义，在单样本学习中，我们只提供一个示例来帮助模型执行任务。尽管这种方法提供的指导比少样本学习要少，但对于简单的任务或LLM已经具备丰富背景知识的主题，它可能很有效。单样本学习的优点是更简单、生成速度更快、计算成本更低（因而API使用成本更低）。然而，对于复杂的任务或需要更深入理解所需结果的情况，少样本学习的效果可能更好。

提示工程已成为一个热门话题。要深入研究这个话题，你可以在互联网上找到许多资源²。

虽然本节探讨了各种可以单独使用的提示工程技巧，但请注意，你可以将这些技巧结合起来使用，以获得更好的效果。开发人员的工作是找到最有效的提示词来解决特定的问题。请记住，提示工程是一个反复试错的迭代过程。

我们已经了解了几种提示工程技巧。采用这些技巧，我们可以引导GPT模型的行为，以使模型给出的结果更好地满足我们的需求。本节将介绍更多技巧，不妨在为GPT模型编写提示词时酌情使用。

注2：推荐两个学习提示工程的网站：Prompt Engineering Guide和Learn Prompting，以便进一步学习。——译者注

1. **指示模型提出更多问题**

在提示词的末尾，询问模型是否理解问题并指示模型提出更多问题。如果你正在构建基于聊天机器人的解决方案，那么这样做非常有效。举例来说，你可以在提示词的末尾添加如下文本：

你清楚地理解我的请求了吗？如果没有，请问我关于上下文的问题。

这样一来，当我回答时，你就能够更高效地执行我所请求的任务。

2. **格式化输出**

有时，你可能希望在一个较长的过程中使用LLM的输出。在这种情况下，输出格式很重要。如果你想要一个JSON输出³，那么模型往往会在JSON代码块之前和之后写入输出。如果你在提示词中说输出必须被json.loads接受，那么模型给出的结果可能更好。这种技巧适用于许多场景。

比如，使用此脚本：

```python
prompt = """
Give a JSON output with 5 names of animals. The output must be 
accepted by json.loads.
"""
chat_completion(prompt, model='gpt-4')
```

我们得到以下JSON代码块。

```json
{
    "animals": [
        "lion",
        "tiger",
        "elephant",
        "giraffe",
        "zebra"
    ]
}
```

注3：截至2023年11月19日，OpenAI在Chat Completion API中新增了响应格式参数，提供了JSON模式的选择，用于确保模型生成的消息是有效的JSON格式。在提示词中说明JSON的输出要求时，同时开启JSON模式可以使模型生成更可靠的结果。——译者注

3. **重复指示**

经验表明，重复指示会取得良好的效果，尤其是当提示词很长时。基本思路是，在提示词中多次添加相同的指令，但每次采用不同的表述方式。这也可以通过负面提示来实现。


4. **使用负面提示**

在文本生成场景中，负面提示是指通过指定不希望在输出中看到的内容来引导模型。

负面提示作为约束或指南，用于滤除某些类型的回答。对于复杂任务，这种技巧特别有用：当以不同的表述方式多次重复指令时，模型往往能够更准确地遵循指令。

继续上一个例子。我们可以在提示词中指示模型不要在JSON代码块之前或之后添加任何内容。

我们在第3章的项目3中使用了负面提示：

```python
Extract the keywords from the following question: {user_question}.
Do not answer anything else, only the keywords.
```

没有这个提示词的话，模型往往不会遵循指示。


5. **添加长度限制**

限制长度通常是不错的做法。如果你只希望模型回答1个词或者10个句子，那么不妨将要求添加到提示词中。这就是我们在第3章的项目1中所做的：我们指示模型用100个单词生成一篇内容翔实的新闻稿。在项目4中，我们所用的提示词也含有长度限制：“如果你能回答问题，回答ANSWER；如果你需要更多信息，回答MORE；如果你无法回答，回答OTHER。只回答一个词。”如果没有最后一句话，模型往往会生成句子，而不会遵循指示。

### 4.2 微调

OpenAI提供了许多可直接使用的GPT模型。尽管这些模型在各种任务上表现出色，但针对特定任务或上下文对它们进行微调，可以进一步提高它们的性能。

#### 4.2.1 开始微调

假设你想为公司创建一个电子邮件自动回复生成器。由于你的公司所在的行业使用专有词汇，因此你希望生成器给出的电子邮件回复保持一定的写作风格。要做到这一点，有两种策略：要么使用之前介绍的提示工程技巧来强制模型输出你想要的文本，要么对现有模型进行微调。本节探讨第二种策略。

对于这个例子，你需要收集大量电子邮件，其中包含关于特定业务领域的数据、客户咨询及针对这些咨询的回复。然后，你可以使用这些数据微调现有模型，以使模型学习公司所用的语言模式和词汇。微调后的模型本质上是基于OpenAI提供的原始模型构建的新模型，其中模型的内部权重被调整，以适应特定问题，从而能够在相关任务上提高准确性。通过对现有模型进行微调，你可以创建一个专门针对特定业务所用语言模式和词汇的电子邮件自动回复生成器。

![image](https://github.com/user-attachments/assets/069dedd0-d8da-4c4d-b482-80afec85defa)


图4 - 3展示了微调过程，也就是使用特定领域的数据集来更新现有GPT模型的内部权重。微调的目标是使新模型能够在特定领域中做出比原始GPT模型更好的预测。需要强调的是，微调后的模型是新模型，它位于OpenAI的服务器上。与之前的模型一样，你必须使用OpenAI API来使用它，因为它无法在本地使用。

即使你使用自己的数据对LLM进行了微调，新模型也仍然保存在OpenAI的服务器上。你需要通过OpenAI API与新模型进行交互，而不是在本地使用它。


1. **针对特定领域的需求调整GPT基础模型**

目前，微调仅适用于davinci、curie、babbage和ada这几个基础模型。这些模型都在准确性和所需资源之间做出了权衡。开发人员可以为应用程序选择最合适的模型：较小的模型（ada和babbage）可能在简单任务或资源有限的应用程序中更快且更具成本效益，较大的模型（curie和davinci）则提供了更强的语言处理和生成能力，从而适用于需要更高准确性的复杂任务。

上述模型不属于InstructGPT系列，它们没有经过RLHF阶段。通过微调这些基础模型，比如根据自定义数据集调整它们的内部权重，你可以针对特定的任务或领域定制模型。虽然没有InstructGPT系列的处理能力，但是它们提供了强大的基础，让你可以利用其预训练的处理能力和生成能力来构建专门的应用程序。

在微调时，必须使用基础模型，而不能使用InstructGPT系列中的模型。

2. **对比微调和少样本学习**

微调是指针对特定任务在一组数据上重新训练现有模型，以提高模型的性能并使其回答更准确。在微调过程中，模型的内部参数得到更新。少样本学习则是通过提示词向模型提供有限数量的好例子，以指导模型根据这些例子给出目标结果。在少样本学习过程中，模型的内部参数不会被修改。

无论是微调和少样本学习，都可以用来增强GPT模型。微调可以帮助我们得到高度专业化的模型，更准确地为特定任务提供与上下文相关的结果。这使得微调非常适合有大量数据可用的场景。这种定制化确保模型生成的内容更符合目标领域的特定语言模式、词汇和语气⁵。

少样本学习是一种更灵活的方法，其数据使用率也更高，因为它不需要重新训练模型。当只有有限的示例可用或需要快速适应不同任务时，这种技巧非常有益。少样本学习让开发人员能够快速设计原型并尝试各种任务，这使其成为许多用例的实用选择。这两种方法的另一个关键选择标准是成本，毕竟使用和训练微调模型更贵。

微调通常需要用到大量数据⁶。可用示例的缺乏往往限制了我们使用这种技巧。为了了解微调所需的数据量，可以假设对于相对简单的任务或仅需稍微调整的模型，通过几百个提示词示例才能获得相应的目标结果。当预训练的GPT模型在任务上表现良好但需要微调以更好地与目标领域对齐时，这种方法是有效的。然而，对于更复杂的任务或需要更多定制化的应用场景，模型可能需要使用成千上万个示例进行训练。前述的电子邮件自动回复生成器正是这样一个应用场景。你还可以针对非常专业的任务微调模型，但这可能需要数十万甚至数百万个示例。这种微调规模可以显著地提高模型的性能，并使模型更好地适应特定领域。

迁移学习是指将从一个领域学到的知识应用于不同但相关的领域。正因为如此，你有时可能会听到人们在谈论微调时提到迁移学习。

#### 4.2.2 使用OpenAI API进行微调

本节将指导你使用OpenAI API来微调LLM。我们将学习如何准备数据、上传数据，并使用OpenAI API创建一个经过微调的模型。

注5：微调除了文中提到的确保模型生成内容更符合目标领域的特定语言模式、词汇和语气，还有一个优势：你可以通过微调缩短每一次提示中重复的指令或提示词以节省成本或降低延迟，模型会记住通过微调获得的“内置”指令。因此，微调后，你可以在不牺牲提示质量的前提下，每次输入更短的提示词。——译者注

注6：截至2023年12月2日，OpenAI已经对微调数据集的需求进行了优化。通常情况下，你只需要提供50 - 100个训练示例进行微调，就会看到明显的改进效果。——译者注 
