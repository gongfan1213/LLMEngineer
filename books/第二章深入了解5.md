### 2.7.2 安全和隐私

在我们撰写本书之时，OpenAI声称不会将作为模型输入的数据用于重新训练，除非用户选择这样做。然而，用户的输入将被保留30天，用于监控和使用合规检查目的。这意味着OpenAI员工和专门的第三方承包商可能会访问你的API数据。

请勿通过OpenAI的端点发送个人信息或密码等敏感数据。我们建议你查阅OpenAI的数据使用规则以获取最新信息，因为使用规则可能会有所变动。如果你是国际用户，请注意，你的个人信息和输入的数据可能会从你的所在地传输到OpenAI在美国的服务器上。这可能在法律方面对你的应用程序创建产生影响。

第3章会进一步详述如何在考虑安全问题和隐私问题的情况下构建基于LLM的应用程序。

### 2.8 其他OpenAI API和功能

除了文本补全功能，OpenAI用户还可以使用其他一些功能。本节会带你探索几个功能，但如果你想深入了解所有API，那么请查看OpenAI的API reference页面。

#### 2.8.1 嵌入

由于模型依赖数学函数，因此它需要数值输入来处理信息。然而，许多元素（如单词和标记）本质上并不是数值。为了解决这个问题，我们用嵌入将这些概念转化为数值向量。通过以数值方式表示这些概念，嵌入使计算机能够更高效地处理它们之间的关系。在某些情况下，嵌入能力可能很有用。OpenAI提供了一个可以将文本转换为数值向量的模型。嵌入端点让开发人员能够获取输入文本的向量表示，然后将该向量表示用作其他ML模型和NLP算法的输入。

截至本书英文版出版之时，OpenAI建议几乎所有的用例都使用其最新模型text-embedding-ada-002。该模型使用起来非常简单，如下所示：

```python
result = openai.Embedding.create(
    model="text-embedding-ada-002", input="your text"
)
```

通过以下方式访问嵌入：

```python
result['data']['embedding']
```

结果嵌入是一个向量，即一个浮点数数组。

请在OpenAI的API reference页面上查看嵌入的完整文档。

嵌入的原则是以某种方式有意义地表示文本字符串，以捕捉其语义相似性。以下是嵌入的一些用例。

- **搜索**：按查询字符串的相关性给结果排序。

- **推荐**：推荐包含与查询字符串相关的文本字符串的文章。

- **聚类**：按相似度为字符串分组。 

- **异常检测**：找到一个与其他字符串无关的文本字符串。

**嵌入如何为ML模型翻译语言**

在ML领域，特别是在处理语言模型时，我们会遇到嵌入这一重要概念。嵌入将分类数据（比如标记，通常是单个单词或多组标记）转换为数值格式，具体而言是实数向量。这种转换是必要的，因为ML模型依赖数值数据，其直接处理分类数据的能力欠佳。

你可以将嵌入视为一种复杂的语言解释器，它将丰富的词汇和句子转换为ML模型能够轻松理解的数值语言。嵌入的一个突出特点是，它能够保持语义相似性。也就是说，含义相近的词语或短语在数值空间中更接近。

在信息检索过程中，这是基础属性。信息检索过程涉及从大型数据集中提取相关信息。鉴于其捕捉语义相似性的方式，嵌入是执行这类操作的绝佳工具。

LLM广泛使用嵌入。通常，这些模型处理约512维的嵌入，从而提供语言数据的高维数值表示。这些维度很深，使得模型能够区分各种复杂的模式。因此，它们在各种语言任务上表现出色，包括翻译、摘要和生成与人类对话相似的文本回应。

嵌入具有这样的属性：如果两段文本具有相似的含义，那么它们的向量表示也是相似的。举例来说，图2-8显示了三个句子。尽管“猫在房子周围追着老鼠跑”和“在房子周围，老鼠被猫追着跑”具有不同的语法结构，但它们的大体意思相同，因此具有相似的嵌入表示。而句子“航天员在轨修理了宇宙飞船”与前面的句子（关于猫和老鼠的句子）无关，并且讨论了完全不同的主题（航天员和宇宙飞船），因此它的嵌入表示明显不同。请注意，为清晰起见，本例将嵌入显示为具有两个维度，但实际上，嵌入通常具有更高的维度，比如512维。

![image](https://github.com/user-attachments/assets/26c09729-80b0-4059-a702-192ae265bce4)


图2-8：三个句子的二维嵌入示例

后续各章将多次提及嵌入API，因为嵌入是使用AI模型处理自然语言的重要工具。

#### 2.8.2 内容审核模型

如前所述，在使用OpenAI模型时，必须遵守OpenAI使用规则。为了帮助你遵守这些规则，OpenAI提供了一个模型来检查内容是否符合使用规则。如果你构建了一个应用程序，其中用户输入将被用作提示词，那么这个模型将非常有用：你可以根据内容审核端点的结果过滤查询。该模型提供分类功能，让你能够针对以下类别搜索内容¹⁹。

- **hate**：内容涉及对种族、性别、民族、宗教、国籍、残疾或种姓的仇恨。

- **hate/threatening**：内容涉及对特定群体的暴力行为或严重伤害。

- **self-harm**：内容涉及自残行为。

- **sexual**：内容涉及性行为（性教育和与健康相关的内容除外）。

- **sexual/minors**：内容同上，但涉及18岁以下的未成年人。

- **violence**：内容涉及崇尚暴力或者给他人造成痛苦或羞辱。

- **violence/graphic**：内容涉及详尽地描绘死亡、暴力或严重的身体伤害。

在这方面，内容审核模型对非英语语言的支持有限。

内容审核模型的端点是openai.Moderation.create，它只有两个可用参数：model和input。有两个内容审核模型可供选择，默认模型是text-moderation-latest，它会随时间自动更新，以确保你始终使用最准确的模型。另一个模型是text-moderation-stable。在更新此模型之前，OpenAI会通知你。

text-moderation-stable模型的准确性可能稍低于text-moderation-latest模型。

以下是使用text-moderation-latest模型的示例：

```python
import openai
# 调用Moderation端点，并使用text-moderation-latest模型
response = openai.Moderation.create(
    model="text-moderation-latest",
    input="I want to kill my neighbor.",
)
```

以下是内容审核结果：

```json
{
    "id": "modr-7AFtIjG7L5jgGIscb7Nut0bH4j0Ig",
    "model": "text-moderation-004",
    "results": [
        {
            "categories": {
                "hate": false,
                "hate/threatening": false,
                "self-harm": false,
                "sexual": false,
                "sexual/minors": false,
                "violence": true,
                "violence/graphic": false
            },
            "category_scores": {
                "hate": 0.0400671623647213,
                "hate/threatening": 3.671687863970874e-06,
                "self-harm": 1.3143378509994363e-06,
                "sexual": 5.508050548996835e-07,
                "sexual/minors": 1.1862029225540027e-07,
                "violence": 0.9461417198181152,
                "violence/graphic": 1.463699845771771e-06
            },
            "flagged": true
        }
    ]
}
```

表2-7解释了输出中的各个字段。

| 字段名称 | 类型 | 描述 |
| ---- | ---- | ---- |
| model | 字符串 | 这是用于预测的模型。在之前的示例中，我们指定使用text-moderation-latest模型，而在输出结果中，使用的是text-moderation-004模型。如果我们使用text-moderation-stable模型调用该方法，则输出结果会使用text-moderation-001模型 |
| flagged | 布尔型 | 如果模型将内容识别为违反了OpenAI的使用规则，那么该值为true，否则为false |
| categories | 字典 | 这包括一个用于违规类别的字典。对于每个类别，如果模型识别到违规行为，则其值为true，否则为false。可以通过print(type(response['results'][0]['categories']))访问该字典 |
| category_scores | 字典 | 该字典包含特定类别的分数，显示模型对输入违规的信心程度。分数范围是0 - 1，分数越高表示信心越足。这些分数不应被视为概率。可以通过print(type(response['results'][0]['category_scores']))访问该字典 |

OpenAI会定期改进内容审核系统。因此，category_scores可能会有所变化，用于确定类别的阈值也可能会改变。

#### 2.8.3 Whisper和DALL·E

除了LLM，OpenAI还提供了其他AI工具。在某些用例中，这些AI工具可以轻松地与GPT模型结合使用。我们在此不介绍它们，因为它们不是本书的重点。但是不用担心，它们的API使用方法与LLM的API使用方法相似。

Whisper是用于语音识别的多功能模型。它是在大型音频数据集上训练的，也是可以执行多语言语音识别、语音翻译和语言识别的多任务模型。OpenAI Whisper项目的GitHub页面提供了一个开源版本。

2021年1月，OpenAI推出了DALL·E，这是一个能够根据自然语言描述创造逼真图像和艺术作品的AI系统。DALL·E 2在技术上进一步提升了分辨率和输入文本理解能力，并添加了新功能。这两个版本的DALL·E是通过对图像及其文本描述进行训练的Transformer模型创建的。你可以通过API和OpenAI的Labs界面试用DALL·E 2²⁰。

### 2.9 小结（含速查清单）

如前所述，OpenAI通过API将其模型作为一项服务提供给用户。在本书中，我们选择使用OpenAI提供的Python库，它是对API的简单封装。借助这个库，我们可以与GPT-4和ChatGPT进行交互：这是构建LLM驱动型应用程序的第一步。然而，使用这些模型涉及几个考虑因素：API密钥管理、定价和隐私。

开始使用LLM之前，我们建议查阅OpenAI的使用规则，并通过Playground来熟悉不同的模型，而无须编写代码。请记住，GPT-3.5 Turbo是ChatGPT背后的模型，它在大多数用例中是最佳选择²¹。

以下是向GPT-3.5 Turbo发送输入消息时可参考的速查清单。

1. 安装openai依赖项。

```bash
pip install openai
```

2. 将API密钥设置为环境变量。

```bash
export OPENAI_API_KEY=sk-(...)
```

3. 在Python中，导入openai。

```python
import openai
```

4. 调用openai.ChatCompletion端点。

```python
response = openai.ChatCompletion.create(
    model="gpt-3.5-turbo",
    messages=[{"role": "user", "content": "Your Input Here"}],
)
```

5. 获取答案。

```python
print(response['choices'][0]['message']['content'])
```

别忘了查看定价页面，并使用tiktoken库估算使用成本。

请注意，不应该通过OpenAI的端点发送敏感数据，例如个人信息或密码。

OpenAI还提供了其他几个模型和工具。你将在后续章节中发现，嵌入端点非常有用，它可以帮助你在应用程序中集成NLP功能。

现在你已经知道如何使用OpenAI的服务，是时候深入了解为何应该使用它们。在第3章中，你将看到各种示例和用例，从而学习如何充分利用GPT-4和ChatGPT。 

注19：截至2023年11月下旬，审核内容新增了harassment类别，内容涉及表达、煽动或推广对任何目标的骚扰言论。——译者注

注20：DALL·E 3已于2023年11月推出。——译者注
注21：2023年11月，OpenAI推出了GPT-4 Turbo和GPT-4 Vision。前者的上下文窗口大小是GPT-3.5 Turbo的30倍以上，后者新增了图像理解能力。请根据具体用例需求选择合适的模型。——译者注 
