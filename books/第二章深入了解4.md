
表2-4：函数对象的详细信息

| 字段名称 | 类型 | 描述 |
| ---- | ---- | ---- |
| name | 字符串（必填） | 函数名 |
| description | 字符串 | 函数描述 |
| parameters | 对象 | 函数所需的参数。这些参数将以JSON Schema格式进行描述 |

来看一个例子。假设我们有一个包含公司产品相关信息的数据库。我们可以定义一个函数来执行对这个数据库的搜索：

```python
# 示例函数
def find_product(sql_query):
    results = [
        {"name": "pen", "color": "blue", "price": 1.99},
        {"name": "pen", "color": "red", "price": 1.78},
    ]
    return results
```

接下来定义函数的规范：

```python
# 函数定义
functions = [
    {
        "name": "find_product",
        "description": "Get a list of products from a sql query",
        "parameters": {
            "type": "object",
            "properties": {
                "sql_query": {
                    "type": "string",
                    "description": "A SQL query",
                },
            },
            "required": ["sql_query"],
        },
    },
]
```

我们可以创建一个对话，并调用ChatCompletion端点：

```python
# 示例问题
user_question = "I need the top 2 products where the price is less than 2.00"
messages = [{"role": "user", "content": user_question}]
# 使用函数定义调用ChatCompletion端点
response = openai.ChatCompletion.create(
    model="gpt-3.5-turbo-0613", messages=messages,
    functions=functions
)
response_message = response["choices"][0]["message"]
messages.append(response_message)
```

我们使用该模型创建了一个查询。如果打印function_call对象，会得到如下结果：

```json
"function_call": {
    "name": "find_product",
    "arguments": "{\"sql_query\": \"SELECT * FROM products WHERE price < 2.00 ORDER BY price ASC LIMIT 2\"}"
}
```

接下来，我们执行该函数并继续对话：

```python
# 调用函数
function_args = json.loads(
    response_message["function_call"]["arguments"]
)
products = find_product(function_args.get("sql_query"))
# 将函数的响应附加到消息中
messages.append(
    {
        "role": "function",
        "name": function_name,
        "content": json.dumps(products),
    }
)
# 将函数的响应格式化为自然语言
response = openai.ChatCompletion.create(
    model="gpt-3.5-turbo-0613",
    messages=messages,
)
```
最后，提取最终的响应并得到以下内容：
```
The top 2 products where the price is less than $2.00 are:
1. Pen (Blue) - Price: $1.99
2. Pen (Red) - Price: $1.78
```
这个简单的例子演示了如何利用函数来构建一个解决方案，使最终用户能够以自然语言与数据库进行交互。你可以使用函数定义将模型限制为按照你希望的方式进行回答，并将其响应集成到应用程序中。

### 2.6 使用其他文本补全模型
如前所述，除了GPT-3和GPT-3.5，OpenAI还提供了其他几个模型。这些模型所用的端点与GPT-4和ChatGPT所用的不同。尽管无论是在价格方面还是在性能方面，GPT-3.5 Turbo模型通常都是最佳选择，但是不妨了解一下如何使用文本补全模型，特别是在微调等用例中，GPT-3文本补全模型是唯一的选择¹⁵。

penAI已经发布了文本补全端点的弃用计划。我们之所以在此介绍这个端点，只是因为基于补全的模型是唯一可以进行微调的模型¹⁶。OpenAI计划在2024年1月之前为基于聊天的模型提供一个解决方案。由于目前尚不可用，我们无法在此提供有关它的描述信息。

文本补全和聊天补全之间有一个重要的区别：两者都能生成文本，但聊天补全更适合于对话。从如下代码片段可以看出，与ChatCompletion端点相比，Completion端点的主要区别在于提示词的格式。基于聊天的模型必须采用对话格式，而基于补全的模型只采用单独的提示词：

```python
import openai
# 调用Completion端点
response = openai.Completion.create(
    model="text-davinci-003", prompt="Hello World!"
)
# 提取响应
print(response["choices"][0]["text"])
```
以上代码片段将输出类似于以下内容的结果：
```
\n\nIt's a pleasure to meet you. I'm new to the world.
```
接下来详细介绍Completion端点的输入选项。

### 2.6.1 Completion端点的输入选项

Completion端点的输入选项集与我们之前在ChatCompletion端点中看到的非常相似。在本节中，我们将讨论主要的输入参数，并考虑提示词的长度对结果的影响。

#### 1. 主要的输入参数

表2-5列出了我们认为最有用的必需参数和一些可选参数。

| 字段名称 | 类型 | 描述 |
| ---- | ---- | ---- |
| model | 字符串（必填） | 所用模型的ID（与ChatCompletion相同）。这是唯一的必需参数 |
| prompt | 字符串或数组（默认值是<|endoftext|>） | 生成补全内容的提示词。它体现了Completion端点与ChatCompletion端点的主要区别。Completion.create应编码为字符串、字符串数组、标记数组或标记数组的数组。如果没有提供该参数，那么模型将从新文档的开头生成文本 |
| max_tokens | 整型 | 在聊天对话中生成的最大标记数。该参数的默认值为16。这个值对于某些用例可能太小，应根据需求进行调整 |
| suffix | 字符串（默认值是null） | 补全之后的文本。该参数不仅允许添加后缀文本，还允许进行插入操作 |

#### 2. 对话长度和标记数量

与聊天模型一样，文本补全模型的费用也取决于输入和输出。对于输入，必须仔细管理prompt参数的长度；如果使用suffix参数，还需要管理它的长度。对于输出，请使用max_tokens参数。它可以帮助你避免费用过高。

#### 3. 可选参数
同样，与ChatCompletion端点一样，可以使用可选参数来进一步调整模型的行为。由于这些参数的用法与ChatCompletion端点中的相同，因此这里不再赘述。请记住，可以使用temperature或n来控制输出，使用max_tokens来控制成本，并使用stream在长文本补全场景中提供更好的用户体验。

### 2.6.2 Completion端点的输出格式
你已经知道了如何使用基于文本的模型。你会发现，这类模型的结果与聊天模型的结果非常相似。以下是Hello World示例程序使用davinci模型后的输出示例。
```json
{
    "choices": [
        {
            "finish_reason": "stop",
            "index": 0,
            "logprobs": null,
            "text": "<br />\n\nHi there! It's great to see you."
        }
    ],
    "created": 1681883111,
    "id": "cmpl-76uutuz1SxOyzaFBoxBnaatGINMLT",
    "model": "text-davinci-003",
    "object": "text_completion",
    "usage": {
        "completion_tokens": 15,
        "prompt_tokens": 3,
        "total_tokens": 18
    }
}
```
这个输出与我们使用聊天模型得到的非常相似。唯一的区别在于choices对象：不再有属性content和role，而有一个包含模型生成文本的属性text。

### 2.7 考虑因素
在广泛使用API之前，应该考虑两个重要因素：成本和数据隐私。

### 2.7.1 定价和标记限制

OpenAI在Pricing页面上列出了模型的定价。请注意，OpenAI不一定及时更新该页面上的定价信息，因此实际费用可能随时间变化。

在我们撰写本书之时，常用OpenAI模型的定价和最大标记数如表2-6所示。

| 系列 | 模型 | 定价 | 最大标记数 |
| ---- | ---- | ---- | ---- |
| 聊天 | gpt-4 | 输入：每千个标记0.03美元<br>输出：每千个标记0.06美元 | 8192 |
| 聊天 | gpt-4-32k | 输入：每千个标记0.06美元<br>输出：每千个标记0.12美元 | 32768 |
| 聊天 | gpt-3.5-turbo | 输入：每千个标记0.0015美元<br>输出：每千个标记0.0020美元 | 4096 |
| 聊天 | gpt-3.5-turbo-16k | 输入：每千个标记0.003美元<br>输出：每千个标记0.004美元 | 16384 |
| 文本补全 | text-davinci-003 | 每千个标记0.02美元 | 4097 |

在表2-6中，有几点需要注意。

text-davinci-003模型的定价是gpt-3.5-turbo模型的10倍以上。由于gpt-3.5-turbo模型也可用于单轮文本补全任务，并且对于这类任务，两个模型的准确性相当，因此我们建议使用gpt-3.5-turbo模型（除非你需要插入、后缀等特殊功能，或者在特定的任务上，text-davinci-003模型的性能更佳）。

gpt-3.5-turbo模型比gpt-4模型便宜。对于许多基本任务来说，二者的表现大同小异。然而，在复杂的推理场景中，gpt-4模型远优于任何先前的模型。

与text-davinci-003模型不同，聊天系列的模型对于输入和输出有不同的定价策略。

gpt-4模型的上下文窗口大小大约是gpt-3.5-turbo模型的两倍，gpt-4-32k模型甚至达到32768个标记，这大概相当于25000个英语单词¹⁸。gpt-4模型可以实现长篇内容创作、高级对话，以及文档搜索和分析，但用户需要相应地付出更高的成本。 

注15：截至2023年11月下旬，GPT-3.5微调功能已完全开放，GPT-4微调功能可通过申请权限开放。——译者注

注16：截至2023年11月下旬，GPT-3.5微调功能已完全开放，GPT-4微调功能可通过申请权限开放。——译者注

注17：截至2023年11月下旬，OpenAI模型的定价已整体下调，具体定价请以OpenAI网站为准。——译者注

注18：OpenAI已经推出了GPT-4 Turbo，其上下文窗口大小达到了128K，是GPT-3.5 Turbo的30倍以上。——译者注 
