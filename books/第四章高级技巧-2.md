### 4.1 提示工程（续）

#### 4.1.1 设计有效的提示词（续）
- **SQL请求**：

  构建简单的SQL查询。

提示词示例如下：

```
Create a SQL request to find all users who live in California and have over 1000 credits.
```

- **类比制造器**：


对两个词进行类比。

提示词示例如下：

```
Create an analogy for this phrase. Questions are arrows in that:
```


- **摘要笔记**：

总结会议纪要。

提示词示例如下：

```
Convert my shorthand into a first-hand account of the meeting:
Tom: Profits up 50%
Jane: New servers are online
Kjel: Need more time to fix software

```

3. **角色**

在撰写提示词时，影响模型的最后一种方式是赋予其一个角色。当然，角色和上下文可以独立使用，但同时使用可以加强对模型输出的控制。在以下示例中，我们赋予模型运动营养专家的角色：

```python
prompt = """
Role: You are a nutritionist designing healthy diets for high-performance athletes. You take into account the nutrition needed for a good recovery.
Context: I do 2 hours of sport a day. I am vegetarian, and I don't like green vegetables. I am conscientious about eating healthily.
Task: Based on your expertise defined in your role, give me a suggestion for a main course for today's lunch. With this suggestion, I also want a table with two columns where each row in the table contains an ingredient from the main course. The first column of the table is the name of the ingredient. The second column of the table is the number of grams of that ingredient needed for one person. Do not give the recipe for preparing the main course.
"""
chat_completion(prompt)
```

我们得到以下结果：


```
Main Course Suggestion: Quinoa and Chickpea Stuffed Bell Peppers
Ingredient Table:
| Ingredient | Grams per Person |
| --- | --- |
| Quinoa | 60 |
| Chickpeas | 100 |
| Bell Peppers | 200 |
| Olive Oil | 10 |
| Onion | 50 |
| Garlic | 5 |
| Tomato | 100 |
| Feta Cheese | 30 |
| Kalamata Olives | 20 |
| Fresh Basil | 5 |
| Salt | 2 |
| Black Pepper | 1 |
```

正如你所见，提示词可用于调整像GPT模型这样的LLM的概率分布集。它们可以被视为模型指南，引导模型生成特定类型的结果。虽然没有必须遵守的提示词设计结构，但不妨考虑结合使用上下文、角色和任务。

注意，这只是一种方法，你完全可以创建不明确定义这些要素的提示词。根据应用程序的具体需求，一些提示词可能采用不同的结构，或者采用更具创造性的方法。因此，不要受限于“上下文 - 任务 - 角色”框架，而应将其视为帮助你有效设计提示词的工具。

#### 4.1.2 逐步思考

我们知道，GPT - 4不擅长计算。比如，它无法计算369 × 1235：

```python
prompt = "How much is 369 * 1235?"
chat_completion(prompt)

```

模型给出的答案是454 965，但正确答案是455 715。GPT - 4不能解决复杂的数学问题吗？请记住，该模型从左侧开始，通过依次预测答案中的每个标记来给出完整的答案。这意味着GPT - 4首先生成最左侧的数字，然后将其作为上下文的一部分生成下一个数字，以此类推，直到形成完整的答案。

挑战在于，每个数字都是独立预测的，与最终的正确值无关。GPT - 4将数字视为标记，它没有数学逻辑。

第5章将探讨OpenAI如何通过插件来增强GPT - 4。一个例子是计算器插件，它可用于进行准确的数学运算。

提高语言模型的推理能力有一个诀窍。比如，当要求模型计算369 × 1235时，我们可以看到模型试图一次性直接回答。考虑到即使是我们自己，也很难在没有纸和笔的情况下计算这个乘法算式，因此我们可以通过提示词鼓励模型进行中间推理。就像我们使用纸和笔计算一样，如果给模型足够的时间进行推理，它也可以解决复杂的问题。

在提示词的末尾添加“让我们逐步思考”这样的话，已被证明可以使模型解决更复杂的推理问题。这种技术称为零样本思维链策略（zero - shot - CoT strategy），由Takeshi Kojima等人在2022年发表的论文“Large Language Models are Zero - Shot Reasoners”中提出。

思维链是指使用提示词鼓励模型逐步模仿推理的技术。零样本这个术语意味着模型不依赖于特定任务的示例来执行这种推理，它已经准备好根据其一般的训练结果来处理新任务。与我们稍后就会讨论的少样本学习等技术不同，零样本学习试图在不需要特定任务示例的情况下进行泛化。

正如我们将看到的，在提示词末尾添加逐步思考的字样（比如示例中的“Let’s think step by step”）后，模型开始通过拆分问题来进行推理。它可能需要一些时间来进行推理，从而解决之前无法在一次尝试中解决的问题。

让我们来看看具体的效果：

```python
prompt = "How much is 369 * 1235? Let’s think step by step."
chat_completion(prompt)
```

模型的输出如下所示：

```
Step 1: Multiply 369 by 5 (the last digit of 1235).
369 * 5 = 1845
Step 2: Multiply 369 by 30 (the second last digit of 1235 is 3, so multiply by 3 and add a 0 at the end).
369 * 30 = 11070
Step 3: Multiply 369 by 200 (the third digit of 1235 is 2, so multiply by 2 and add two 0s at the end).
369 * 200 = 73800
Step 4: Multiply 369 by 1000 (the first digit of 1235 is 1, so multiply by 1 and add three 0s at the end).
369 * 1000 = 369000
Step 5: Add the results from steps 1 to 4.
1845 + 11070 + 73800 + 369000 = 455715
So, 369 * 1235 = 455,715.
```

模型所用的方法发生了显著的改变。现在它将主要问题分解为更小、更容易管理的步骤，而不是试图直接解决问题。

尽管提示模型逐步思考，但仍需注意，要仔细评估其回答，因为GPT - 4并非绝对可靠。对于更复杂的算式，比如3695 × 123 548，即使使用这个技巧，GPT - 4也可能无法算出正确答案。

当然，我们通常无法仅凭一个例子判断某个技巧是否奏效，或许我们只是比较幸运而已。在关于各种数学问题的基准测试中，实验证明这个技巧有助于显著提高GPT模型的准确性。尽管这个技巧对大多数数学问题有效，但并不适用于所有情况。论文“Large Language Models are Zero - Shot Reasoners”的作者发现，它对于多步算术问题、涉及符号推理的问题、涉及策略的问题和其他涉及推理的问题非常有效。然而，它对于模型回答常识性问题没有显著效果。

#### 4.1.3 实现少样本学习

少样本学习（few - shot learning）是由Tom B. Brown等人在论文“Language Models Are Few - Shot Learners”中提出的，它指的是LLM仅通过提示词中的几个示例就能进行概括并给出有价值的结果。在使用少样本学习技巧时，你可以给模型提供几个示例，如图4 - 2所示。这些示例指导模型输出所需的格式。

图4 - 2：包含几个示例的提示词

```
提示词：
I go home --> 🏠 go 🏠
my dog is sad --> my 🐕 is 😢
I run fast --> 🏃‍♂️ run 🏃‍♂️
I love my wife --> 😍❤️ my wife
the girl plays with the ball --> the 👧 plays with the ⚽
The boy writes a letter to a girl --> 
示例：上述每行的转换示例
任务：完成最后一行的转换
```

在本例中，我们要求LLM将特定的单词转换成表情符号。很难想象如何通过提示词给模型下达这种“指令”。但是通过少样本学习，这变得很容易。给模型一些例子，它将自动尝试复制它们的模式：

```python
prompt = """
I go home --> 🏠 go 🏠
my dog is sad --> my 🐕 is 😢
I run fast --> 🏃‍♂️ run 🏃‍♂️
I love my wife --> 😍❤️ my wife
the girl plays with the ball --> the 👧 plays with the ⚽
The boy writes a letter to a girl --> 
"""
chat_completion(prompt)
```

我们得到以下输出消息：

```
The 👦✉️ a 📝 to a 👧
```
少样本学习技巧提供了具有目标输出的输入示例。然后，在最后一行，我们提供了想让模型完成的提示词。这个提示词与之前的示例具有相同的形式。模型将根据给定示例的模式执行操作。

我们可以看到，仅凭几个示例，模型就能够复现模式。通过利用在训练阶段所获得的海量知识，LLM可以根据少量例子迅速适应并生成准确的答案。 
